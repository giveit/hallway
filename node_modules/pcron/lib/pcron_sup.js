/*
* Copyright (C) 2012 Singly, Inc. All Rights Reserved.
*
* Redistribution and use in source and binary forms, with or without
* modification, are permitted provided that the following conditions are met:
*    * Redistributions of source code must retain the above copyright
*      notice, this list of conditions and the following disclaimer.
*    * Redistributions in binary form must reproduce the above copyright
*      notice, this list of conditions and the following disclaimer in the
*      documentation and/or other materials provided with the distribution.
*    * Neither the name of the Locker Project nor the
*      names of its contributors may be used to endorse or promote products
*      derived from this software without specific prior written permission.
*
* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
* ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
* WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
* DISCLAIMED. IN NO EVENT SHALL THE LOCKER PROJECT BE LIABLE FOR ANY
* DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
* (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
* LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
* ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
* (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
* SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

var _ = require("underscore");
var pcron = require("pcron");
var pcronWorkList = require("./pcron_worklist");
var childProcess = require("child_process");
var redis = require("redis");

// Config settings:
// services = [string()]
// moduleName = string()
// notifChannel = string()
// workerId = string()
//
// redis = { "host" : string(), "port" : int() }
//
// heartbeatInterval  = int() ms
// watchdogInterval   = int() ms
// childStopInterval  = int() ms
// maxConcurrentProfiles = int ()
//
// workerRefreshInterval = int() seconds


function checkConfig(cfg) {
  if (!cfg.moduleName)
    return new Error("pcron_sup: No worker module specified");

  if (!cfg.workerId)
    return new Error("pcron_sup: WorkerID must be specified");

  if (!cfg.services || cfg.services.length === 0)
    return new Error("pcron_sup: List of services to monitor must be specified");

  cfg.heartbeatInterval = cfg.heartbeatInterval || 45000;    // 45 secs
  cfg.watchdogInterval = cfg.watchdogInterval || 10000;      // 10 secs
  cfg.childStopInterval = cfg.childStopInterval || 5000;     // 5 secs
  cfg.maxConcurrentProfiles = cfg.maxConcurrentProfiles || 5; // 5 profiles

  cfg.workerRefreshInterval = cfg.workerRefreshInterval || cfg.heartbeatInterval;

  if (cfg.heartbeatInterval >= cfg.maxRuntimeInterval)
    return new Error("pcron_sup: heartbeatInterval must be < maxRuntimeInterval");

  if (cfg.watchdogInterval >= cfg.heartbeatInterval)
    return new Error("pcron_sup: watchdogInterval must be < heartbeatInterval");

  if (cfg.heartbeatInterval >= (cfg.workerRefreshInterval * 1000))
    return new Error("pcron_sup: heartbeatInterval must < workerRefreshInterval");

  if (!cfg.redis) cfg.redis = {host: "localhost", port: 6379};
  cfg.redis.host = cfg.redis.host || "localhost";
  cfg.redis.port = cfg.redis.port || 6379;
  cfg.redis.database = cfg.redis.database || 0;

  cfg.spawnArgs = cfg.spawnArgs || [];

  return null;
}

var __sup_next_id = 0;

function start(config, cbDone) {
  var sup = {};

  sup.id = __sup_next_id++;

  // Check the config
  var configError = checkConfig(config);
  if (configError !== null) return cbDone(configError);

  // Convert the array of services to a set to enable efficient
  // handling of notifications on services we don't care about
  // (see .onPcronNotify)
  var serviceSet = _.reduce(config.services, function (acc, svc)
                            { acc[svc + "_schedule"] = true; return acc; }, {});

  // Initialize redis connections
  var rclient = redis.createClient(config.redis.port, config.redis.host);
  var rpubsub = redis.createClient(config.redis.port, config.redis.host);

  // Initialize pcron with our redis connection
  var pcronInst = pcron.init(rclient);

  sup.moduleName = config.moduleName;

  sup.workerId = config.workerId;

  var schedules = {};           // Table of [Schedule, PendingCount]
  var activeSchedule = null;    // Schedule to poll next
  var workList;

  var childHandle = null;
  var childState = null;
  var childAlivetime = 0;       // Time at which child last sent ALIVE message
  var childStopTimeout = null;

  var childWorkerIds = [];

  function resetWorkerIds() {
    childWorkerIds = [];
    for (var i = 0; i < config.maxConcurrentProfiles; i++) {
      childWorkerIds.push(sup.workerId + "_" + i);
    }
  }

  resetWorkerIds();

  var stoppedCb = null;
  var stopping = false;

  function watchdog() {
    // If the child isn't in the running state, noop
    if (childState !== "running") return;

    // If the child process has not checked in with the last ALIVE seconds
    //
    // Give up on the current profile. This means:
    // 1. Terminate the child with extreme predjudice
    // 2. Decrement tick for the current schedule
    var now = Date.now();

    if (now - childAlivetime > config.heartbeatInterval) {
      console.log("No heartbeat in " + (now - childAlivetime) + "ms. Last heartbeat: " + childAlivetime + " now: " + now);
      terminateChild("heartbeatTimeout");
    }
  }

  var watchdogInterval = setInterval(watchdog, config.watchdogInterval);

  function terminateChild(reason) {
    // If no child is running or system is already mid-terminate, noop out.
    if (!childHandle || childState === "stopping") {
      if (stoppedCb) stoppedCb();
      return;
    }

    // Notify any interested observers
    rclient.publish("pcron_sup", "terminateChild " + sup.workerId + " " + reason);

    // Issue the TERM to let the child know that it's time to shutdown. We'll
    // also schedule a callback after childStopInterval milliseconds to follow
    // up with a KILL, if the child doesn't exit before then.
    var pid = childHandle.pid;
    childHandle.kill();
    childState = "stopping";

    childStopTimeout = setTimeout(function () {
      if (childHandle && childHandle.pid === pid) {
        childHandle.kill('SIGKILL');
      }
    }, config.childStopInterval);
  }

  sup.stop = function (cbStopped) {
    stoppedCb = cbStopped;
    stopping = true;

    // Terminate all connections to redis
    rclient.end();
    rpubsub.end();

    // Cancel watchdog
    clearInterval(watchdogInterval);

    // Terminate child process
    terminateChild("sup_stop");
  };


  function onPcronNotify(channel, message) {
    // Messages should be of form: "pending Count Schedule"
    var parts = message.split(" ");
    if (parts[0] === "pending") {
      var count = parseInt(parts[1], 10);
      var service = parts[2];
      if (serviceSet[service] === true) {
        // Update our table of schedule state and then evaluate it at
        // next opportunity. Note that this may overwrite what we _think_
        // the state is, as the worker uses the state as a scratchpad to
        // figure out what to do next
        schedules[service] = count;
        process.nextTick(evaluateWork);
      }
    } else {
      console.log("Unexpected pcron message on channel " + channel + " : " +
                  message);
    }
  }

  rpubsub.on("message", onPcronNotify);

  function onChildExit(code, signal) {
    // If a hard terminate is scheduled, cancel it
    if (childStopTimeout) {
      clearTimeout(childStopTimeout);
      childStopTimeout = null;
    }

    // Child exited; notify observers of unusual circumstances
    if (code !== null && code !== 0) {
      rclient.publish("pcron_sup", "childExit " + sup.workerId + " " + childHandle.pid + " " + code);
    } else if (signal) {
      rclient.publish("pcron_sup", "childKilled " + sup.workerId + " " + childHandle.pid + " " + signal);
    }

    // Cleanup internal state and look for more work to do on next tick
    childHandle = null;
    childState = null;
    resetWorkerIds();

    // If we're not stopping, look for more work
    if (!stopping) {
      // Wait 1 second before looking for more work; breathing room for cases
      // where child is constantly dying
      setTimeout(function () { process.nextTick(evaluateWork); }, 1000);
    } else {
      // Stopping -- notify observer
      if (stoppedCb) stoppedCb();
    }
  }

  function onChildMessage(msg) {
    if (msg.type === "alive") {
      childAlivetime = Date.now();
    } else if (msg.type === "ready") {
      childState = "running";
      process.nextTick(evaluateWork);
    } else if (msg.type === "completed") {
      // Child has completed processing a profile
      var now = Date.now();
      pcronInst.finish_work(msg.service, msg.profile, msg.workerId, now,
                            msg.nextRun, function () {
                              // TODO: Do we care about redis failure here? I
                              // suspect not...
                              if (childState == "running") {
                                childWorkerIds.push(msg.workerId);
                              }
                              process.nextTick(evaluateWork);
                            });
    } else {
      console.log("Unexpected msg from pcron child " + sup.moduleName + " (" +
                  childHandle.pid + "): " + JSON.stringify(msg));
    }
  }

  function evaluateWork() {
    // Child is already fully loaded
    if (childWorkerIds.length === 0) return;

    // Build the worklist if it's empty
    if (!workList) workList = pcronWorkList.init(schedules, 10);

    // Child is not active (or not running); get the next schedule
    // to process
    activeSchedule = workList.next();
    if (activeSchedule !== null) {
      startWork();
    } else {
      workList = null;
    }
  }

  function startWork() {
    // Spin up a child process if it's not already running
    if (childHandle === null) {
      // TODO: Pass in env, cwd, etc.
      childHandle = childProcess.fork(sup.moduleName, config.spawnArgs);
      childHandle.on('exit', onChildExit);
      childHandle.on('message', onChildMessage);
      childState = "pending";
      childAlivetime = Date.now();
      rclient.publish("pcron_sup", "startChild " + sup.workerId + " " + sup.moduleName + " " +
                      childHandle.pid);
    }

    // If a schedule has some work and the child is idle, get some work
    if (activeSchedule !== null && childState === "running" && childWorkerIds.length > 0) {
      var now = Date.now();
      var workerId = childWorkerIds.pop();
      pcronInst.start_work(activeSchedule, now, workerId, config.workerRefreshInterval,
                           function (err, result) {
                             // TODO: What should happen when the Redis call fails?!

                             // It's possible that in the time we've issued the
                             // start_work and the return that the child has failed
                             // a heartbeat test and been killed. So, we need to
                             // double-check that the child is still in the right
                             // state before we proceed.
                             if (childState !== "running") return;

                             if (result !== null) {
                               childHandle.send({type: "work", id: result,
                                                 workerId: workerId});
                             } else {
                               // Null result indicates that the schedule in
                               // question has no work remaining. Update the
                               // workList and look for work at next opportunity
                               childWorkerIds.push(workerId);
                               if (workList) workList.skip();
                             }
                             process.nextTick(evaluateWork);
                           });
    }
  }

  //
  // *** Final initialization ***
  //
  // Select the configured database in redis
  rclient.select(config.redis.database, function (err) {
    if (err) cbDone(err);

    // For each of the schedules, get their initial state
    pcronInst.schedule_info(config.services, Date.now(), function (err, result) {
      if (err) return cbDone(err);
      schedules = JSON.parse(result);

      // Subscribe to the notif channel and invoke cbDone when complete
      rpubsub.subscribe("pcron_schedules", function (err) {
        if (err) return cbDone(err, null);
        process.nextTick(evaluateWork);
        cbDone(null, sup);
      });
    });
  });
}

exports.start = start;
